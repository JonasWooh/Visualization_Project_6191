{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YouTube & TikTok Trends — Interactive EDA Dashboard (Dash)\n",
    "\n",
    "This notebook contains a fully runnable Dash app that reads the CSV and renders the 5-question exploration with interactive filters.\n",
    "\n",
    "**Data path**: set `DATA_PATH` env var or place the file at `./data/youtube_shorts_tiktok_trends_2025.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import dash\n",
    "from dash import dcc, html, Input, Output, State\n",
    "\n",
    "px.defaults.template = \"plotly_white\"\n",
    "px.defaults.width = 1150\n",
    "px.defaults.height = 700\n",
    "\n",
    "def make_sparse_marks(vmin, vmax, step=10, fmt=str):\n",
    "    vmin = int(np.floor(vmin)); vmax = int(np.ceil(vmax))\n",
    "    return {v: fmt(v) for v in range(vmin, vmax + 1, step)}\n",
    "\n",
    "def fmt_si(x):\n",
    "    try:\n",
    "        return f\"{pd.to_numeric(x):~s}\"  # will be used mainly for tickformat via Plotly\n",
    "    except Exception:\n",
    "        return str(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CSV: D:\\Viz_Project\\data\\youtube_shorts_tiktok_trends_2025.csv\n",
      "Rows=48,079 | duration range ~ [10, 89] | countries=30 | categories=19 | platforms=2\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = Path(\"../data/youtube_shorts_tiktok_trends_2025.csv\").resolve()\n",
    "\n",
    "\n",
    "print(\"Using CSV:\", DATA_PATH)\n",
    "if not DATA_PATH.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"CSV not found at: {DATA_PATH}\\n\"\n",
    "        \"Check your project structure: Viz_Project/code (this notebook) and Viz_Project/data (CSV).\"\n",
    "    )\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# --- basic casting to ensure numeric dtypes ---------------------------------\n",
    "num_cols = [\n",
    "    \"duration_sec\",\"views\",\"likes\",\"comments\",\"shares\",\"saves\",\"engagement_rate\",\n",
    "    \"engagement_like_rate\",\"engagement_comment_rate\",\"engagement_share_rate\",\n",
    "    \"avg_watch_time_sec\",\"completion_rate\",\"upload_hour\",\"trend_duration_days\",\n",
    "    \"engagement_velocity\"\n",
    "]\n",
    "for c in num_cols:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "# --- normalize publish_dayofweek & weekend ----------------------------------\n",
    "WEEK_ORDER = [\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\"Sunday\"]\n",
    "\n",
    "if \"publish_dayofweek\" in df.columns:\n",
    "    s = df[\"publish_dayofweek\"]\n",
    "\n",
    "    if pd.api.types.is_numeric_dtype(s):\n",
    "        mapping = {0:\"Monday\",1:\"Tuesday\",2:\"Wednesday\",3:\"Thursday\",4:\"Friday\",5:\"Saturday\",6:\"Sunday\"}\n",
    "        s = s.map(mapping)\n",
    "    else:\n",
    "        s = s.astype(str).str.strip().str.lower()\n",
    "        alias = {\n",
    "            \"mon\":\"monday\",\"monday\":\"monday\",\"0\":\"monday\",\n",
    "            \"tue\":\"tuesday\",\"tuesday\":\"tuesday\",\"1\":\"tuesday\",\n",
    "            \"wed\":\"wednesday\",\"wednesday\":\"wednesday\",\"2\":\"wednesday\",\n",
    "            \"thu\":\"thursday\",\"thursday\":\"thursday\",\"3\":\"thursday\",\n",
    "            \"fri\":\"friday\",\"friday\":\"friday\",\"4\":\"friday\",\n",
    "            \"sat\":\"saturday\",\"saturday\":\"saturday\",\"5\":\"saturday\",\n",
    "            \"sun\":\"sunday\",\"sunday\":\"sunday\",\"6\":\"sunday\",\n",
    "        }\n",
    "        s = s.map(lambda x: alias.get(x, x)).str.capitalize()\n",
    "\n",
    "    df[\"publish_dayofweek\"] = pd.Categorical(s, categories=WEEK_ORDER, ordered=True)\n",
    "\n",
    "if \"is_weekend\" not in df.columns:\n",
    "    if \"publish_dayofweek\" in df.columns:\n",
    "        df[\"is_weekend\"] = df[\"publish_dayofweek\"].isin([\"Saturday\",\"Sunday\"]).astype(int)\n",
    "    else:\n",
    "        df[\"is_weekend\"] = 0\n",
    "\n",
    "# --- safe ranges for sliders (robust to outliers / missing) -----------------\n",
    "if \"duration_sec\" in df.columns and df[\"duration_sec\"].notna().any():\n",
    "    dur_min = int(np.nanquantile(df[\"duration_sec\"], 0.01))\n",
    "    dur_max = int(np.nanquantile(df[\"duration_sec\"], 0.99))\n",
    "    dur_min = max(0, dur_min)\n",
    "    dur_max = min(180, max(dur_min + 1, dur_max))\n",
    "else:\n",
    "    dur_min, dur_max = 0, 90\n",
    "\n",
    "hour_min, hour_max = 0, 23\n",
    "\n",
    "# --- dropdown options --------------------------------------\n",
    "country_opts = []\n",
    "if \"country\" in df.columns:\n",
    "    top_c = df[\"country\"].value_counts().head(40).reset_index()\n",
    "    top_c.columns = [\"country\", \"n\"]\n",
    "    country_opts = [{\"label\": f\"{r.country} (N={int(r.n):,})\", \"value\": r.country} for _, r in top_c.iterrows()]\n",
    "\n",
    "category_opts = []\n",
    "if \"category\" in df.columns:\n",
    "    top_cat = df[\"category\"].value_counts().head(40).reset_index()\n",
    "    top_cat.columns = [\"category\", \"n\"]\n",
    "    category_opts = [{\"label\": f\"{r.category} (N={int(r.n):,})\", \"value\": r.category} for _, r in top_cat.iterrows()]\n",
    "\n",
    "platform_opts = []\n",
    "if \"platform\" in df.columns:\n",
    "    platform_opts = [{\"label\": p, \"value\": p} for p in df[\"platform\"].dropna().unique()]\n",
    "\n",
    "print(\n",
    "    f\"Rows={len(df):,} | duration range ~ [{dur_min}, {dur_max}] | \"\n",
    "    f\"countries={len(country_opts)} | categories={len(category_opts)} | platforms={len(platform_opts)}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Helper: apply filters --------------------------------------------------\n",
    "def apply_filters(dfin, platforms, countries, categories, dur_range, hour_range):\n",
    "    d = dfin\n",
    "    if platforms:\n",
    "        d = d[d['platform'].isin(platforms)]\n",
    "    if countries:\n",
    "        d = d[d['country'].isin(countries)]\n",
    "    if categories:\n",
    "        d = d[d['category'].isin(categories)]\n",
    "    if 'duration_sec' in d.columns and dur_range:\n",
    "        d = d[(d['duration_sec'] >= dur_range[0]) & (d['duration_sec'] <= dur_range[1])]\n",
    "    if 'upload_hour' in d.columns and hour_range:\n",
    "        d = d[(d['upload_hour'] >= hour_range[0]) & (d['upload_hour'] <= hour_range[1])]\n",
    "    return d.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Figure builders with tidy axes/labels ---------------------------------\n",
    "def fig_q1_1_platform_box(d):\n",
    "    title = \"Q1-1 Engagement Rate by Platform\"\n",
    "    n_by = d.groupby('platform', dropna=False)['engagement_rate'].size().to_dict()\n",
    "    fig = px.box(d, x='platform', y='engagement_rate', color='platform', points=False, title=title)\n",
    "    # annotate medians\n",
    "    meds = d.groupby('platform')['engagement_rate'].median()\n",
    "    for plat, val in meds.items():\n",
    "        fig.add_annotation(x=plat, y=val, text=f\"{val:.1%}\", showarrow=False, yshift=10, font=dict(size=12))\n",
    "    fig.update_yaxes(tickformat=\".0%\", nticks=6)\n",
    "    fig.update_layout(margin=dict(l=70, r=20, t=60, b=50), legend_title_text=\"platform\",\n",
    "                      title=dict(text=f\"Q1-1 Engagement Rate by Platform — \"\n",
    "                                    f\"{', '.join([f'{k} N={v:,}' for k,v in n_by.items()])}\"))\n",
    "    return fig\n",
    "\n",
    "def fig_q1_2_structure_box(d):\n",
    "    cols = ['engagement_rate','engagement_like_rate','engagement_comment_rate','engagement_share_rate']\n",
    "    m = d.melt(id_vars=['platform'], value_vars=[c for c in cols if c in d.columns],\n",
    "               var_name='metric', value_name='value')\n",
    "    fig = px.box(m, x='metric', y='value', color='platform', points=False,\n",
    "                 category_orders={'metric': cols},\n",
    "                 title='Q1-2 Engagement Structure by Platform')\n",
    "    fig.update_yaxes(tickformat=\".0%\", nticks=6)\n",
    "    fig.update_layout(margin=dict(l=70, r=20, t=60, b=60))\n",
    "    return fig\n",
    "\n",
    "def fig_q1_3_views_likes(d):\n",
    "    dd = d[(d['views'] > 0) & (d['likes'] > 0)].copy()\n",
    "    if len(dd) > 12000:\n",
    "        dd = dd.groupby('platform', group_keys=False).apply(lambda x: x.sample(min(6000, len(x)), random_state=42))\n",
    "\n",
    "    fig = px.scatter(\n",
    "        dd, x='views', y='likes', color='platform', opacity=0.55,\n",
    "        title='Q1-3 Views vs Likes by Platform (log–log; slope annotated)'\n",
    "    )\n",
    "\n",
    "    # Build decade ticks explicitly to avoid the log+dtick text replication bug.\n",
    "    vx_min = np.floor(np.log10(dd['views'].min()))\n",
    "    vx_max = np.ceil(np.log10(dd['views'].max()))\n",
    "    vy_min = np.floor(np.log10(dd['likes'].min()))\n",
    "    vy_max = np.ceil(np.log10(dd['likes'].max()))\n",
    "    x_tickvals = [10 ** e for e in range(int(vx_min), int(vx_max) + 1)]\n",
    "    y_tickvals = [10 ** e for e in range(int(vy_min), int(vy_max) + 1)]\n",
    "    def si(n):  # 1_000 -> '1k', 1_000_000 -> '1M'\n",
    "        for u, t in [(1e12,'T'),(1e9,'B'),(1e6,'M'),(1e3,'k')]:\n",
    "            if n >= u: return f\"{int(n/u)}{t}\"\n",
    "        return str(int(n))\n",
    "\n",
    "    fig.update_xaxes(type='log', tickmode='array', tickvals=x_tickvals, ticktext=[si(v) for v in x_tickvals])\n",
    "    fig.update_yaxes(type='log', tickmode='array', tickvals=y_tickvals, ticktext=[si(v) for v in y_tickvals])\n",
    "\n",
    "    # Per-platform slope on log10 scale\n",
    "    txts = []\n",
    "    for plat, g in dd.groupby('platform'):\n",
    "        x = np.log10(g['views'])\n",
    "        y = np.log10(g['likes'])\n",
    "        if len(g) > 10:\n",
    "            k = np.polyfit(x, y, 1)[0]\n",
    "            txts.append(f\"{plat}: slope≈{k:.4f}\")\n",
    "\n",
    "    if txts:\n",
    "        fig.add_annotation(\n",
    "            x=0, y=0, xref='paper', yref='paper',\n",
    "            xanchor='left', yanchor='bottom',\n",
    "            text=' | '.join(txts),\n",
    "            showarrow=False,\n",
    "            font=dict(size=12),\n",
    "            bgcolor='rgba(255,255,255,0.6)',\n",
    "            bordercolor='rgba(0,0,0,0.08)'\n",
    "        )\n",
    "\n",
    "    fig.update_layout(margin=dict(l=70, r=20, t=60, b=50))\n",
    "    return fig\n",
    "\n",
    "\n",
    "def fig_q2_1_hour_week_heat(d):\n",
    "    if 'publish_dayofweek' not in d.columns or 'upload_hour' not in d.columns:\n",
    "        return go.Figure()\n",
    "    heat = d.groupby(['publish_dayofweek','upload_hour'], as_index=False)['engagement_rate'].median()\n",
    "    # Build pivot with full 24h x 7 days grid\n",
    "    week_order = ['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']\n",
    "    hours = list(range(0,24))\n",
    "    grid = (heat.pivot(index='publish_dayofweek', columns='upload_hour', values='engagement_rate')\n",
    "                .reindex(index=week_order, columns=hours))\n",
    "    fig = px.imshow(grid, aspect='auto', color_continuous_scale='Viridis', origin='upper',\n",
    "                    labels=dict(x='Hour', y='Weekday', color='Median'))\n",
    "    fig.update_layout(title='Q2-1 Median Engagement — Hour × Weekday',\n",
    "                      margin=dict(l=70, r=20, t=60, b=50))\n",
    "    fig.update_xaxes(tickmode='array', tickvals=list(range(0,24,2)))\n",
    "    fig.update_coloraxes(colorbar_tickformat='.1%')\n",
    "    return fig\n",
    "\n",
    "def fig_q2_2_weekend_box(d):\n",
    "    dd = d.copy()\n",
    "    dd['weekend'] = np.where(dd['is_weekend']==1, 'Weekend', 'Weekday')\n",
    "    fig = px.box(dd, x='weekend', y='engagement_rate', points=False,\n",
    "                 title='Q2-2 Engagement Rate — Weekend vs Weekday')\n",
    "    med = dd.groupby('weekend')['engagement_rate'].median()\n",
    "    for k,v in med.items():\n",
    "        fig.add_annotation(x=k, y=v, text=f\"{v:.1%}\", showarrow=False, yshift=10)\n",
    "    fig.update_yaxes(tickformat='.0%', nticks=6)\n",
    "    fig.update_layout(margin=dict(l=70, r=20, t=60, b=50))\n",
    "    return fig\n",
    "\n",
    "def fig_q3_1_duration_completion(d):\n",
    "    fig = px.density_heatmap(d, x='duration_sec', y='completion_rate', nbinsx=28, nbinsy=24,\n",
    "                             color_continuous_scale='Viridis',\n",
    "                             title='Q3-1 Duration vs Completion Rate (Density)')\n",
    "    fig.update_xaxes(tickmode='linear', dtick=10)\n",
    "    fig.update_yaxes(tickformat='.0%', nticks=8)\n",
    "    fig.update_coloraxes(colorbar_title='Count')\n",
    "    fig.update_layout(margin=dict(l=70, r=20, t=60, b=50))\n",
    "    return fig\n",
    "\n",
    "def fig_q3_2_duration_watchtime(d):\n",
    "    dd = d.copy()\n",
    "    if len(dd) > 12000:\n",
    "        dd = dd.groupby('platform', group_keys=False).apply(lambda x: x.sample(min(6000, len(x)), random_state=42))\n",
    "    fig = px.scatter(dd, x='duration_sec', y='avg_watch_time_sec', color='platform', opacity=0.55,\n",
    "                     title='Q3-2 Duration vs Avg Watch Time (by Platform)')\n",
    "    fig.update_xaxes(tickmode='linear', dtick=10)\n",
    "    fig.update_layout(margin=dict(l=70, r=20, t=60, b=50))\n",
    "    return fig\n",
    "\n",
    "def fig_q4_1_top_categories(d, topn=20):\n",
    "    if 'category' not in d.columns: return go.Figure()\n",
    "    g = (d.groupby('category')\n",
    "           .agg(median_eng=('engagement_rate','median'), N=('engagement_rate','size'))\n",
    "           .reset_index())\n",
    "    g = g.sort_values('median_eng', ascending=False).head(topn)\n",
    "    g['label'] = g['category'] + g['N'].map(lambda x: f\" (N={x:,})\")\n",
    "    fig = px.bar(g, y='label', x='median_eng', orientation='h', title='Q4-1 Top-20 Categories — Median Engagement (sorted by median; N = sample size)')\n",
    "    fig.update_xaxes(tickformat='.0%', nticks=6)\n",
    "    fig.update_layout(margin=dict(l=150, r=20, t=60, b=40))\n",
    "    return fig\n",
    "\n",
    "def fig_q4_2_top_hashtags(d, topn=30):\n",
    "    if 'hashtag' not in d.columns: return go.Figure()\n",
    "    g = (d.groupby('hashtag')\n",
    "           .agg(median_share=('engagement_share_rate','median'), N=('engagement_share_rate','size'))\n",
    "           .reset_index())\n",
    "    g = g.sort_values('median_share', ascending=False).head(topn)\n",
    "    g['label'] = g['hashtag'] + g['N'].map(lambda x: f\"  (N={x:,})\")\n",
    "    fig = px.bar(g, y='label', x='median_share', orientation='h', title='Q4-2 Top-30 Hashtags — Median Share Rate (sorted by median; N = sample size)')\n",
    "    fig.update_xaxes(tickformat='.1%', nticks=6)\n",
    "    fig.update_layout(margin=dict(l=220, r=20, t=60, b=40))\n",
    "    return fig\n",
    "\n",
    "def fig_q5_1_creator_tier(d):\n",
    "    if 'creator_tier' not in d.columns: return go.Figure()\n",
    "    fig = px.box(d, x='creator_tier', y='engagement_rate', points=False, title='Q5-1 Engagement Rate by Creator Tier')\n",
    "    med = d.groupby('creator_tier')['engagement_rate'].median()\n",
    "    for k,v in med.items():\n",
    "        fig.add_annotation(x=k, y=v, text=f\"{v:.1%}\", showarrow=False, yshift=10)\n",
    "    fig.update_yaxes(tickformat='.0%', nticks=6)\n",
    "    fig.update_layout(margin=dict(l=70, r=20, t=60, b=50))\n",
    "    return fig\n",
    "\n",
    "def fig_q5_2_trend_velocity(d):\n",
    "    cols_exist = set(['trend_duration_days','engagement_velocity','views']).issubset(d.columns)\n",
    "    if not cols_exist: return go.Figure()\n",
    "    dd = d.copy()\n",
    "    if len(dd) > 12000:\n",
    "        dd = dd.groupby('platform', group_keys=False).apply(lambda x: x.sample(min(6000, len(x)), random_state=42))\n",
    "    fig = px.scatter(dd, x='trend_duration_days', y='engagement_velocity', color='platform', size='views',\n",
    "                     size_max=18, opacity=0.6,\n",
    "                     title='Q5-2 Trend Duration vs Engagement Velocity (log y; size=views)')\n",
    "    fig.update_yaxes(type='log', tickformat='~s', dtick=1)\n",
    "    fig.update_layout(margin=dict(l=70, r=20, t=60, b=50))\n",
    "    return fig\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Build Dash layout ------------------------------------------------------\n",
    "app = dash.Dash(__name__)\n",
    "app.title = \"YouTube & TikTok Trends — EDA\"\n",
    "\n",
    "controls = html.Div([\n",
    "    html.H1(\"YouTube & TikTok Trends — Interactive EDA Dashboard\"),\n",
    "    html.P(\"Data source: YouTube Shorts & TikTok Trends 2025 (local CSV)\", className='muted'),\n",
    "\n",
    "    html.Div([\n",
    "        html.Div([\n",
    "            html.Label(\"Platform\"),\n",
    "            dcc.Dropdown(id='platform-dd', options=platform_opts,\n",
    "                         value=[o['value'] for o in platform_opts], multi=True)\n",
    "        ], style={\"flex\":\"1\",\"minWidth\":\"240px\",\"marginRight\":\"12px\"}),\n",
    "        html.Div([\n",
    "            html.Label(\"Country (top options)\"),\n",
    "            dcc.Dropdown(id='country-dd', options=country_opts, multi=True, placeholder=\"Select...\")\n",
    "        ], style={\"flex\":\"1\",\"minWidth\":\"260px\",\"marginRight\":\"12px\"}),\n",
    "        html.Div([\n",
    "            html.Label(\"Category (optional)\"),\n",
    "            dcc.Dropdown(id='category-dd', options=category_opts, multi=True, placeholder=\"Select...\")\n",
    "        ], style={\"flex\":\"1\",\"minWidth\":\"260px\"}),\n",
    "    ], style={\"display\":\"flex\",\"flexWrap\":\"wrap\",\"marginBottom\":\"8px\"}),\n",
    "\n",
    "    html.Div([\n",
    "        html.Div([\n",
    "            html.Label(\"Duration (sec)\"),\n",
    "            dcc.RangeSlider(id='duration-slider', min=dur_min, max=dur_max, step=1,\n",
    "                            value=[dur_min, dur_max],\n",
    "                            marks=make_sparse_marks(dur_min, dur_max, step=10, fmt=lambda v: f\"{v}\"),\n",
    "                            allowCross=False, dots=False,\n",
    "                            tooltip={\"placement\":\"bottom\",\"always_visible\":False}),\n",
    "        ], style={\"flex\":\"1\",\"minWidth\":\"420px\",\"marginRight\":\"12px\"}),\n",
    "\n",
    "        html.Div([\n",
    "            html.Label(\"Upload hour\"),\n",
    "            dcc.RangeSlider(id='hour-slider', min=0, max=23, step=1, value=[0,23],\n",
    "                            marks={h:f\"{h}\" for h in range(0,24,3)}, allowCross=False, dots=False,\n",
    "                            tooltip={\"placement\":\"bottom\",\"always_visible\":False}),\n",
    "        ], style={\"flex\":\"1\",\"minWidth\":\"420px\"}),\n",
    "    ], style={\"display\":\"flex\",\"flexWrap\":\"wrap\",\"marginBottom\":\"12px\"}),\n",
    "], style={\"marginBottom\":\"8px\"})\n",
    "\n",
    "kpi_row = html.Div([\n",
    "    html.Div([html.Div(\"Rows\"), html.H2(id='kpi-rows'), html.Div(\"After filters\")]),\n",
    "    html.Div([html.Div(\"Median engagement\"), html.H2(id='kpi-med-eng'), html.Div(\"\")]),\n",
    "    html.Div([html.Div(\"Median duration\"), html.H2(id='kpi-med-dur'), html.Div(\"\")]),\n",
    "    html.Div([html.Div(\"Median completion\"), html.H2(id='kpi-med-comp'), html.Div(\"\")]),\n",
    "], id='kpi-row', style={\"display\":\"grid\",\"gridTemplateColumns\":\"repeat(4, 1fr)\",\"gap\":\"14px\",\"marginBottom\":\"12px\"})\n",
    "\n",
    "tabs = dcc.Tabs(id='tabs-container', value='q1', children=[\n",
    "    dcc.Tab(label='Q1 Platform Differences', value='q1', className='tab', selected_className='tab--selected', children=[\n",
    "        html.Div([\n",
    "            dcc.Graph(id='fig-q1-1', className='dash-graph'),\n",
    "            dcc.Graph(id='fig-q1-2', className='dash-graph'),\n",
    "            dcc.Graph(id='fig-q1-3', className='dash-graph'),\n",
    "        ])\n",
    "    ]),\n",
    "    dcc.Tab(label='Q2 When to Post', value='q2', className='tab', selected_className='tab--selected', children=[\n",
    "        html.Div([\n",
    "            dcc.Graph(id='fig-q2-1', className='dash-graph'),\n",
    "            dcc.Graph(id='fig-q2-2', className='dash-graph'),\n",
    "        ])\n",
    "    ]),\n",
    "    dcc.Tab(label='Q3 Length & Retention', value='q3', className='tab', selected_className='tab--selected', children=[\n",
    "        html.Div([\n",
    "            dcc.Graph(id='fig-q3-1', className='dash-graph'),\n",
    "            dcc.Graph(id='fig-q3-2', className='dash-graph'),\n",
    "        ])\n",
    "    ]),\n",
    "    dcc.Tab(label='Q4 Topics & Hashtags', value='q4', className='tab', selected_className='tab--selected', children=[\n",
    "        html.Div([\n",
    "            dcc.Graph(id='fig-q4-1', className='dash-graph'),\n",
    "            dcc.Graph(id='fig-q4-2', className='dash-graph'),\n",
    "        ])\n",
    "    ]),\n",
    "    dcc.Tab(label='Q5 Creators & Trend Cycle', value='q5', className='tab', selected_className='tab--selected', children=[\n",
    "        html.Div([\n",
    "            dcc.Graph(id='fig-q5-1', className='dash-graph'),\n",
    "            dcc.Graph(id='fig-q5-2', className='dash-graph'),\n",
    "        ])\n",
    "    ]),\n",
    "])\n",
    "\n",
    "\n",
    "viz_wrap = html.Div(\n",
    "    [kpi_row, tabs],\n",
    "    id='viz-wrap'\n",
    ")\n",
    "\n",
    "app.layout = html.Div([\n",
    "    controls,\n",
    "    viz_wrap\n",
    "], style={\"maxWidth\":\"1200px\",\"margin\":\"18px auto\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Callbacks --------------------------------------------------------------\n",
    "@app.callback(\n",
    "    [Output('kpi-rows','children'), Output('kpi-med-eng','children'), Output('kpi-med-dur','children'), Output('kpi-med-comp','children'),\n",
    "     Output('fig-q1-1','figure'), Output('fig-q1-2','figure'), Output('fig-q1-3','figure'),\n",
    "     Output('fig-q2-1','figure'), Output('fig-q2-2','figure'),\n",
    "     Output('fig-q3-1','figure'), Output('fig-q3-2','figure'),\n",
    "     Output('fig-q4-1','figure'), Output('fig-q4-2','figure'),\n",
    "     Output('fig-q5-1','figure'), Output('fig-q5-2','figure')],\n",
    "    [Input('platform-dd','value'), Input('country-dd','value'), Input('category-dd','value'),\n",
    "     Input('duration-slider','value'), Input('hour-slider','value')]\n",
    ")\n",
    "def update_all(platforms, countries, categories, dur_rng, hour_rng):\n",
    "    d = apply_filters(df, platforms, countries, categories, dur_rng, hour_rng)\n",
    "    # KPIs\n",
    "    rows = f\"{len(d):,.0f}\"\n",
    "    med_eng = f\"{d['engagement_rate'].median():.1%}\" if 'engagement_rate' in d else \"—\"\n",
    "    med_dur = f\"{d['duration_sec'].median():.0f}s\" if 'duration_sec' in d else \"—\"\n",
    "    med_comp = f\"{d['completion_rate'].median():.1%}\" if 'completion_rate' in d else \"—\"\n",
    "    # figs\n",
    "    f_q1_1 = fig_q1_1_platform_box(d)\n",
    "    f_q1_2 = fig_q1_2_structure_box(d)\n",
    "    f_q1_3 = fig_q1_3_views_likes(d)\n",
    "    f_q2_1 = fig_q2_1_hour_week_heat(d)\n",
    "    f_q2_2 = fig_q2_2_weekend_box(d)\n",
    "    f_q3_1 = fig_q3_1_duration_completion(d)\n",
    "    f_q3_2 = fig_q3_2_duration_watchtime(d)\n",
    "    f_q4_1 = fig_q4_1_top_categories(d)\n",
    "    f_q4_2 = fig_q4_2_top_hashtags(d)\n",
    "    f_q5_1 = fig_q5_1_creator_tier(d)\n",
    "    f_q5_2 = fig_q5_2_trend_velocity(d)\n",
    "    return rows, med_eng, med_dur, med_comp, f_q1_1, f_q1_2, f_q1_3, f_q2_1, f_q2_2, f_q3_1, f_q3_2, f_q4_1, f_q4_2, f_q5_1, f_q5_2\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('viz-wrap', 'style'),\n",
    "    Input('platform-dd', 'value')\n",
    ")\n",
    "def toggle_viz_wrap(platforms):\n",
    "    if not platforms:\n",
    "        return {'display': 'none'}\n",
    "    return {}\n",
    "\n",
    "    \n",
    "@app.callback(\n",
    "    Output('country-dd', 'disabled'),\n",
    "    Output('category-dd', 'disabled'),\n",
    "    Output('duration-slider', 'disabled'),\n",
    "    Output('hour-slider', 'disabled'),\n",
    "    Output('country-dd', 'value'),\n",
    "    Output('category-dd', 'value'),\n",
    "    Output('country-dd', 'placeholder'),\n",
    "    Output('category-dd', 'placeholder'),\n",
    "    Input('platform-dd', 'value'),\n",
    "    prevent_initial_call=True\n",
    ")\n",
    "def disable_and_hint(platforms):\n",
    "    if not platforms:\n",
    "        msg = \"Please select platform(s) first\"\n",
    "        return (\n",
    "            True, True, True, True,  \n",
    "            None, None,              \n",
    "            msg, msg                  \n",
    "        )\n",
    "    return (\n",
    "        False, False, False, False,\n",
    "        dash.no_update, dash.no_update,\n",
    "        \"Select...\", \"Select...\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1d864988d90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app defined. Run `app.run_server()` in a separate cell to start.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JonasWu\\AppData\\Local\\Temp\\ipykernel_39156\\1238687705.py:30: FutureWarning:\n",
      "\n",
      "DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "\n",
      "C:\\Users\\JonasWu\\AppData\\Local\\Temp\\ipykernel_39156\\1238687705.py:30: FutureWarning:\n",
      "\n",
      "DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "\n",
      "C:\\Users\\JonasWu\\AppData\\Local\\Temp\\ipykernel_39156\\1238687705.py:79: FutureWarning:\n",
      "\n",
      "The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "\n",
      "C:\\Users\\JonasWu\\AppData\\Local\\Temp\\ipykernel_39156\\1238687705.py:79: FutureWarning:\n",
      "\n",
      "The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "\n",
      "C:\\Users\\JonasWu\\AppData\\Local\\Temp\\ipykernel_39156\\1238687705.py:118: FutureWarning:\n",
      "\n",
      "DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "\n",
      "C:\\Users\\JonasWu\\AppData\\Local\\Temp\\ipykernel_39156\\1238687705.py:118: FutureWarning:\n",
      "\n",
      "DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "\n",
      "C:\\Users\\JonasWu\\AppData\\Local\\Temp\\ipykernel_39156\\1238687705.py:164: FutureWarning:\n",
      "\n",
      "DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "\n",
      "C:\\Users\\JonasWu\\AppData\\Local\\Temp\\ipykernel_39156\\1238687705.py:164: FutureWarning:\n",
      "\n",
      "DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "\n",
      "C:\\Users\\JonasWu\\AppData\\Local\\Temp\\ipykernel_39156\\1238687705.py:30: FutureWarning:\n",
      "\n",
      "DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "\n",
      "C:\\Users\\JonasWu\\AppData\\Local\\Temp\\ipykernel_39156\\1238687705.py:79: FutureWarning:\n",
      "\n",
      "The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "\n",
      "C:\\Users\\JonasWu\\AppData\\Local\\Temp\\ipykernel_39156\\1238687705.py:118: FutureWarning:\n",
      "\n",
      "DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "\n",
      "C:\\Users\\JonasWu\\AppData\\Local\\Temp\\ipykernel_39156\\1238687705.py:164: FutureWarning:\n",
      "\n",
      "DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "\n",
      "C:\\Users\\JonasWu\\AppData\\Local\\Temp\\ipykernel_39156\\1238687705.py:30: FutureWarning:\n",
      "\n",
      "DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "\n",
      "C:\\Users\\JonasWu\\AppData\\Local\\Temp\\ipykernel_39156\\1238687705.py:79: FutureWarning:\n",
      "\n",
      "The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "\n",
      "C:\\Users\\JonasWu\\AppData\\Local\\Temp\\ipykernel_39156\\1238687705.py:118: FutureWarning:\n",
      "\n",
      "DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "\n",
      "C:\\Users\\JonasWu\\AppData\\Local\\Temp\\ipykernel_39156\\1238687705.py:164: FutureWarning:\n",
      "\n",
      "DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "\n",
      "C:\\Users\\JonasWu\\AppData\\Local\\Temp\\ipykernel_39156\\1238687705.py:30: FutureWarning:\n",
      "\n",
      "DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "\n",
      "C:\\Users\\JonasWu\\AppData\\Local\\Temp\\ipykernel_39156\\1238687705.py:79: FutureWarning:\n",
      "\n",
      "The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "\n",
      "C:\\Users\\JonasWu\\AppData\\Local\\Temp\\ipykernel_39156\\1238687705.py:118: FutureWarning:\n",
      "\n",
      "DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "\n",
      "C:\\Users\\JonasWu\\AppData\\Local\\Temp\\ipykernel_39156\\1238687705.py:164: FutureWarning:\n",
      "\n",
      "DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "\n",
      "C:\\Users\\JonasWu\\AppData\\Local\\Temp\\ipykernel_39156\\1238687705.py:30: FutureWarning:\n",
      "\n",
      "DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "\n",
      "C:\\Users\\JonasWu\\AppData\\Local\\Temp\\ipykernel_39156\\1238687705.py:79: FutureWarning:\n",
      "\n",
      "The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "\n",
      "C:\\Users\\JonasWu\\AppData\\Local\\Temp\\ipykernel_39156\\1238687705.py:118: FutureWarning:\n",
      "\n",
      "DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "\n",
      "C:\\Users\\JonasWu\\AppData\\Local\\Temp\\ipykernel_39156\\1238687705.py:164: FutureWarning:\n",
      "\n",
      "DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "\n",
      "C:\\Users\\JonasWu\\AppData\\Local\\Temp\\ipykernel_39156\\1238687705.py:30: FutureWarning:\n",
      "\n",
      "DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "\n",
      "C:\\Users\\JonasWu\\AppData\\Local\\Temp\\ipykernel_39156\\1238687705.py:79: FutureWarning:\n",
      "\n",
      "The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "\n",
      "C:\\Users\\JonasWu\\AppData\\Local\\Temp\\ipykernel_39156\\1238687705.py:118: FutureWarning:\n",
      "\n",
      "DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "\n",
      "C:\\Users\\JonasWu\\AppData\\Local\\Temp\\ipykernel_39156\\1238687705.py:164: FutureWarning:\n",
      "\n",
      "DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "\n",
      "C:\\Users\\JonasWu\\AppData\\Local\\Temp\\ipykernel_39156\\1238687705.py:30: FutureWarning:\n",
      "\n",
      "DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "\n",
      "C:\\Users\\JonasWu\\AppData\\Local\\Temp\\ipykernel_39156\\1238687705.py:79: FutureWarning:\n",
      "\n",
      "The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "\n",
      "C:\\Users\\JonasWu\\AppData\\Local\\Temp\\ipykernel_39156\\1238687705.py:118: FutureWarning:\n",
      "\n",
      "DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "\n",
      "C:\\Users\\JonasWu\\AppData\\Local\\Temp\\ipykernel_39156\\1238687705.py:164: FutureWarning:\n",
      "\n",
      "DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Run server (uncomment to run inside notebook) -------------------------\n",
    "app.run_server(debug=True)\n",
    "print(\"Dash app defined. Run `app.run_server()` in a separate cell to start.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "viz_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
